# -*- coding: utf-8 -*-
"""pokeproject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10vO2nX1XHDcsDgAQPSX5Twt5286wvc2g
"""

data = []
titles = 0
f = open('gen9ou-0-1.txt','r')
for i in f.readlines():
    info = i.replace(" ", "").split("|")
    if len(info) == 1:
      battles = info[0]
      if battles.find('Totalbattles:') != -1:
        total_battles = battles[battles.find('Totalbattles:') + 13:]
    elif titles == 0:
      column1 = info[1]
      column2 = info[2]
      column3 = info[3]
      titles = 1
    else:
      usage_percent = info[3]
      int_percent = float(usage_percent[:len(usage_percent) - 1])
      data.append({
        column1: info[1],
        column2: info[2],
        column3: int_percent,
      })
f.close()
print(data)
#print(total_battles)
#print(int_percent)

import pandas as pd
import altair as alt

usage_data = pd.DataFrame(data)
#usage_data
alt.Chart(usage_data.iloc[:20]).mark_bar().encode(
    alt.X('Pokemon:N', sort='-y'),
    alt.Y('Usage%:Q'),
    #color=,
    tooltip=['Usage%:Q', 'Rank:O'],
).interactive().properties(
    title = 'Top Pokemon By Usage'
)

## Generate Full Data Dictionary ##
full_data_dict = {}
data_list = ['gen9ou-0-1', 'gen9ou-0-2', 'gen9ou-0-3', 'gen9ou-1500-1',
             'gen9ou-1500-2', 'gen9ou-1500-3', 'gen9ou-1695-1', 'gen9ou-1695-2',
             'gen9ou-1695-3', 'gen9ou-1825-1', 'gen9ou-1825-2', 'gen9ou-1825-3',
             'gen9ou-0-4', 'gen9ou-0-5', 'gen9ou-0-6', 'gen9ou-1500-4',
             'gen9ou-1500-5', 'gen9ou-1500-6', 'gen9ou-1695-4', 'gen9ou-1695-5',
             'gen9ou-1695-6', 'gen9ou-1825-4', 'gen9ou-1825-5', 'gen9ou-1825-6',
             'gen9ou-0-7', 'gen9ou-0-8', 'gen9ou-0-9', 'gen9ou-1500-7',
             'gen9ou-1500-8', 'gen9ou-1500-9', 'gen9ou-1695-7', 'gen9ou-1695-8',
             'gen9ou-1695-9', 'gen9ou-1825-7', 'gen9ou-1825-8', 'gen9ou-1825-9',
             'gen9ou-0-10', 'gen9ou-1500-10', 'gen9ou-1695-10',  'gen9ou-1825-10',
             'gen9ou-0-11', 'gen9ou-1500-11', 'gen9ou-1695-11',  'gen9ou-1825-11',
             'gen9ou-0-12', 'gen9ou-1500-12', 'gen9ou-1695-12',  'gen9ou-1825-12',
             'gen9ou-0-13', 'gen9ou-1500-13', 'gen9ou-1695-13',  'gen9ou-1825-13']
for data_file in data_list:
  usage_dict = []
  titles = 0
  top100 = 0
  f = open((data_file + '.txt'),'r')
  for i in f.readlines():
    info = i.replace(" ", "").split("|")
    if len(info) == 1:
      battles = info[0]
      if battles.find('Totalbattles:') != -1:
        total_battles = battles[battles.find('Totalbattles:') + 13:]
    elif titles == 0:
      column1 = info[1]
      column2 = info[2]
      column3 = info[3]
      column4 = info[4]
      titles = 1
    else:
      usage_percent = info[3]
      int_percent = float(usage_percent[:len(usage_percent) - 1])
      if top100 < 100:
        usage_dict.append({
          column1: info[1],
          column2: info[2],
          column3: int_percent,
          column4: info[4]
        })
        top100 += 1
  f.close()
  full_data_dict[data_file] = usage_dict

print(full_data_dict)

## Making Usage DataFrame ##
usage = []
pokemon = 'GreatTusk'
for gen in full_data_dict.keys():
  helper = gen[gen.find('-') + 1:]
  weight = helper[:helper.find('-')]
  cycle = helper[helper.find('-') + 1:]
  for poke_data in full_data_dict[gen]:
    if poke_data['Pokemon'] == pokemon:
      usage.append({
        'Cycle': int(cycle),
        'Weight': weight,
        'Rank': int(poke_data['Rank']),
        'Usage%': poke_data['Usage%'],
        'Raw Usage': int(poke_data['Raw'])
      })
print(usage)
usage_dataframe = pd.DataFrame(usage)
usage_dataframe
#print(usage_dataframe['Month'].min())

weight_list = [0, 1500, 1695, 1825]
final_dict = []
for i in range(usage_dataframe['Cycle'].min(), usage_dataframe['Cycle'].max() + 1):
  cycle_sort = usage_dataframe.loc[usage_dataframe['Cycle'] == i]
  data_dict = {}
  #data_dict['Cycle'] = i
  #data_dict['Raw Usage'] = cycle_sort['Raw Usage'].min()
  for index in cycle_sort.index:
    weight = usage_dataframe.iloc[index]['Weight']
    #rank_name = str(weight) + ' Rank'
    usage_name = str(weight) + ' Usage%'
    #data_dict[rank_name] = cycle_sort['Rank'][index]
    data_dict[usage_name] = cycle_sort['Usage%'][index]
  final_dict.append(data_dict)
analysis_df = pd.DataFrame(final_dict)
analysis_df = analysis_df.fillna(0)
analysis_df

stats = analysis_df.iloc[:len(analysis_df) - 1]
usage = analysis_df.iloc[1:]['0 Usage%']

#print(stats)

from sklearn.model_selection import train_test_split

train_and_validation_stats, test_stats, train_and_validation_usage, test_usage = \
    train_test_split(stats, usage, test_size=0.2)
train_stats, validation_stats, train_usage, validation_usage = \
    train_test_split(train_and_validation_stats, train_and_validation_usage, test_size=.125)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler().fit(train_stats, train_usage)

train_stats = scaler.transform(train_stats)
validation_stats = scaler.transform(validation_stats)
test_stats = scaler.transform(test_stats)

import numpy as np
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error

l2_lambdas = np.logspace(-5, 5, 11, base = 10)
data = []
for l2 in l2_lambdas:
  ridge_model = Ridge(l2).fit(train_stats, train_usage)
  train_rmse = np.sqrt(mean_squared_error(train_usage, ridge_model.predict(train_stats)))
  validation_rmse = np.sqrt(mean_squared_error(validation_usage, ridge_model.predict(validation_stats)))
  data.append({
      'l2_penalty': l2,
      'model': ridge_model,
      'train_rmse': train_rmse,
      'validation_rmse': validation_rmse
  })

ridge_usage = pd.DataFrame(data)
ridge_usage

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

# Plot the validation RMSE as a blue line with dots
plt.plot(ridge_usage['l2_penalty'], ridge_usage['validation_rmse'],
         'b-^', label='Validation')
# Plot the train RMSE as a red line dots
plt.plot(ridge_usage['l2_penalty'], ridge_usage['train_rmse'],
         'r-o', label='Train')

# Make the x-axis log scale for readability
plt.xscale('log')

# Label the axes and make a legend
plt.xlabel('l2_penalty')
plt.ylabel('RMSE')
plt.legend()

features = ['Raw Usage', '0 Usage%', '1500 Usage%',
            '1695 Usage%', '1825 Usage%']
row = ridge_usage.loc[ridge_usage['validation_rmse'].idxmin()]
feats = list(zip(features, row['model'].coef_))
print(*feats, sep = "\n")

#from sklearn.linear_model import Lasso

#l1_lambdas = np.logspace(1, 7, 7, base=10)
#data = []
#for l1 in l1_lambdas:
#  lasso_model = Lasso(l1).fit(train_stats, train_usage)
#  train_rmse = np.sqrt(mean_squared_error(train_usage, lasso_model.predict(train_stats)))
#  validation_rmse = np.sqrt(mean_squared_error(validation_usage, lasso_model.predict(validation_stats)))
#  data.append({
#      'l1_penalty': l1,
#      'model': lasso_model,
#      'train_rmse': train_rmse,
#      'validation_rmse': validation_rmse
#  })

#lasso_usage = pd.DataFrame(data)

#plt.plot(lasso_usage['l1_penalty'], lasso_usage['validation_rmse'],
         #'b-^', label='Validation')

#plt.plot(lasso_usage['l1_penalty'], lasso_usage['train_rmse'],
         #'r-o', label='Train')

#plt.xscale('log')

#plt.xlabel('l1_penalty')
#plt.ylabel('RMSE')
#plt.legend()

#lasso_row = lasso_usage.loc[lasso_usage['validation_rmse'].idxmin()]
#feats = list(zip(features, row['model'].coef_))
#print(*feats, sep = "\n")
#print(pd.DataFrame(test_stats))

best_model = row['model']
best_model.fit(train_stats, train_usage.values)
inp = analysis_df.tail(1)
test_inp = analysis_df.head(1)
#print(test_inp)
predict_input = scaler.transform(inp)
prediction = best_model.predict(predict_input)
print(prediction)